# backend/source/ai/trainFirstETA.py

import os
import sys
import time
import torch
import argparse
import pandas as pd
import torch.nn as nn
from collections import defaultdict
from datetime import datetime, timedelta
from torch.utils.data import DataLoader

# === ê²½ë¡œ ì„¤ì • ===
BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..")); sys.path.append(BASE_DIR)
MODEL_DIR = os.path.join(BASE_DIR, "data", "model", "firstETA")
ODEL_SAVE_PATH_1 = None
MODEL_SAVE_PATH_2 = None
SELF_REVIEW_PATH = None
REPLAY_PATH = None
YESTERDAY_MODEL_PATH_2 = None
from source.ai.FirstETAModel import FirstETAModel

# === í•˜ì´í¼íŒŒë¼ë¯¸í„° ===
EPOCHS = 15
BATCH_SIZE = 512
LR = 0.001

# === ë””ë°”ì´ìŠ¤ ì„¤ì • ===
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def train_model(phase: str):
    # === phaseì— ë”°ë¼ í•™ìŠµìš© parquet ê²½ë¡œ ì„ íƒ ===
    if phase == "self_review":
        parquet_path = SELF_REVIEW_PATH
        model_load_path = YESTERDAY_MODEL_PATH_2
        model_save_path = MODEL_SAVE_PATH_1
    elif phase == "replay":
        parquet_path = REPLAY_PATH
        model_load_path = MODEL_SAVE_PATH_1
        model_save_path = MODEL_SAVE_PATH_2
    else:
        raise ValueError("Invalid phase. Use 'self_review' or 'replay'.")

    print(f"[INFO] Loading {phase} dataset: {parquet_path}")
    df = pd.read_parquet(parquet_path)  # parquet íŒŒì¼ ì½ê¸°
    
    # ğŸ”¥ ord ì»¬ëŸ¼ì„ ë¯¸ë¦¬ GPUì— tensorë¡œ ì˜¬ë ¤ë‘  (indexing ì‹œ ì˜¤ë¥˜ ë°©ì§€)
    ord_tensor = torch.tensor(df["ord"].values, dtype=torch.float32).to(device)

    # === ëª¨ë¸ ì •ì˜ ë° ì „ë‚  ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ===
    model = FirstETAModel().to(device)
    if os.path.exists(model_load_path):
        print(f"[INFO] Loading previous model from: {model_load_path}")
        model.load_state_dict(torch.load(model_load_path, map_location=device))
    else:
        print(f"[INFO] No previous model found at {model_load_path}. Initializing new model.")
    optimizer = torch.optim.Adam(model.parameters(), lr=LR)

    # x_ë¡œ ì‹œì‘í•˜ëŠ” ëª¨ë“  columnì„ featureë¡œ ê°„ì£¼
    x_cols = [col for col in df.columns if col.startswith("x_")]

    # self_reviewì¼ ë•ŒëŠ” prev_pred_elapsedê°€ ë°˜ë“œì‹œ ìˆì–´ì•¼ í•¨
    if phase == "self_review":
        assert "x_prev_pred_elapsed" in x_cols, "self_reviewì¸ë° x_prev_pred_elapsedê°€ ì—†ìŒ"

    y_col = "y"

    # ë”•ì…”ë„ˆë¦¬ë¡œ feature êµ¬ì„±
    x_dict = {}
    for col in x_cols:
        key = col.replace("x_", "")
        
        # torch dtype ì§€ì •
        if df[col].dtype in ["int64", "int32"]:
            tensor = torch.tensor(df[col].values, dtype=torch.long)
        else:
            tensor = torch.tensor(df[col].values, dtype=torch.float32)
        
        # [B] â†’ [B, 1] ë³€í™˜
        if tensor.dim() == 1 and tensor.dtype == torch.float32:
            tensor = tensor.unsqueeze(1)

        x_dict[key] = tensor.to(device)

    y = torch.tensor(df[y_col].values, dtype=torch.float32).unsqueeze(1).to(device)

    # datasetì€ ë¦¬ìŠ¤íŠ¸(zip) ê¸°ë°˜ìœ¼ë¡œ êµ¬ì„±
    dataset = list(zip(*(list(x_dict.values()) + [y])))
    keys = list(x_dict.keys())

    # === í•™ìŠµ ë£¨í”„ ===
    model.train()
    for epoch in range(EPOCHS):
        total_loss = 0
        for batch in DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True):
            *x_vals, batch_y = batch
            batch_x = dict(zip(keys, x_vals))
            
            optimizer.zero_grad()

            # forward pass
            pred_mean, pred_log_var = model(batch_x, phase=phase)

            # ê¸°ë³¸ heteroscedastic loss ê³„ì‚°
            hetero_loss = ((batch_y - pred_mean) ** 2 * torch.exp(-pred_log_var) + pred_log_var).mean()
            loss = hetero_loss

            # self-reviewì˜ ê²½ìš° residual penalty ì¶”ê°€
            if phase == "self_review":
                prev_pred = batch_x["prev_pred_elapsed"].detach().unsqueeze(1)
                penalty = nn.functional.relu(batch_y - prev_pred).mean()
                loss = hetero_loss + 0.3 * penalty
            
            # ranking loss ì¶”ê°€ (ìˆœì„œ ë³´ì¥)
            if "trip_group_id" in df.columns and "ord" in df.columns:
                trip_to_indices = defaultdict(list)
                for idx, trip in enumerate(df["trip_group_id"].values):
                    trip_to_indices[trip].append(idx)
                
                ranking_loss = 0
                count = 0
                for indices in trip_to_indices.values():
                    if len(indices) < 2:
                        continue

                    # 1. ord ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ëœ index ë¦¬ìŠ¤íŠ¸ ì–»ê¸°
                    sorted_indices = sorted(indices, key=lambda idx: df["ord"].iloc[idx])
                    sorted_indices_tensor = torch.tensor(sorted_indices, dtype=torch.long, device=device)

                    # 2. ì •ë ¬ëœ ordì™€ ì˜ˆì¸¡ê°’ ê°€ì ¸ì˜¤ê¸°
                    ords = ord_tensor[sorted_indices_tensor]
                    preds = pred_mean[sorted_indices].squeeze()

                    # 3. ìˆœì„œëŒ€ë¡œ loss ê³„ì‚° (ë‹¨, ê°™ì€ ordëŠ” ë¬´ì‹œ)
                    for i in range(len(ords) - 1):
                        if ords[i] < ords[i + 1]:  # ë™ë¥ ì€ ìŠ¤í‚µ
                            ranking_loss += nn.functional.relu(preds[i] - preds[i + 1])
                            count += 1     
                            
                if count > 0:
                    ranking_loss = ranking_loss / count
                    loss += 0.1 * ranking_loss
                
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        # ì—í­ë‹¹ í‰ê·  lossì™€ ìµœëŒ€ ì˜ˆì¸¡ê°’ ì¶œë ¥
        print(f"Epoch {epoch+1}/{EPOCHS}, Loss: {total_loss/len(dataset):.4f}, Max pred: {pred_mean.max().item():.2f}")

    # === ëª¨ë¸ ì €ì¥ ===
    os.makedirs(os.path.dirname(model_save_path), exist_ok=True)
    torch.save(model.state_dict(), model_save_path)
    print(f"[INFO] Saved model to {model_save_path}")

# === main í•¨ìˆ˜ ì§„ì…ì  ===
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--mode", required=True, choices=["self_review", "replay"], help="í•™ìŠµ ë‹¨ê³„: self_review ë˜ëŠ” replay")
    parser.add_argument("--date", required=True, help="í•™ìŠµ ë‚ ì§œ (YYYYMMDD)")
    args = parser.parse_args()

    DATE = args.date
    YESTERDAY = (datetime.strptime(DATE, "%Y%m%d") - timedelta(days=1)).strftime("%Y%m%d")
    
    MODEL_SAVE_PATH_1 = os.path.join(MODEL_DIR, "self_review", f"{DATE}.pth")
    MODEL_SAVE_PATH_2 = os.path.join(MODEL_DIR, "replay", f"{DATE}.pth")
    SELF_REVIEW_PATH = os.path.join(BASE_DIR, "data", "preprocessed", "first_train", "self_review", f"{DATE}.parquet")
    REPLAY_PATH = os.path.join(BASE_DIR, "data", "preprocessed", "first_train", "replay", f"{DATE}.parquet")
    YESTERDAY_MODEL_PATH_2 = os.path.join(MODEL_DIR, "replay", f"{YESTERDAY}.pth")

    now = time.time()
    train_model(args.mode)
    print("ì´ í•™ìŠµ ì‹œê°„: ", time.time() - now, "sec")